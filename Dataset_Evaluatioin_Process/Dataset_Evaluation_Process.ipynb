{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d58d9d",
   "metadata": {},
   "source": [
    "# Dataset Evaluation Process\n",
    "## Systematic Selection for Data Science Portfolio\n",
    "\n",
    "**Date:** June 28, 2025  \n",
    "**Purpose:** Evaluate 6 available datasets to select the optimal one for portfolio development  \n",
    "**Methodology:** Based on Data Quality, Business Relevance, and Technical Complexity\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Evaluation Objective\n",
    "\n",
    "This notebook systematically evaluates all available datasets to identify which one best demonstrates data science skills while providing meaningful business insights for potential employers.\n",
    "\n",
    "### Evaluation Criteria:\n",
    "1. **Data Quality Assessment** \n",
    "2. **Business Relevance Evaluation**   \n",
    "3. **Technical Complexity & Skill Showcase** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec331018",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We'll import pandas for data manipulation, numpy for numerical operations, and other libraries needed for our comprehensive dataset evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "958e848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n",
      "📊 Ready to begin systematic dataset evaluation...\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for dataset evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"📊 Ready to begin systematic dataset evaluation...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5387bdd",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment Functions\n",
    "\n",
    "We'll define comprehensive functions to calculate and display data quality metrics for each dataset. This systematic approach ensures consistent evaluation across all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2fd525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data quality metrics function defined!\n"
     ]
    }
   ],
   "source": [
    "def calculate_data_quality_metrics(df, dataset_name):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive data quality metrics for a dataset\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to evaluate\n",
    "    - dataset_name: string name of the dataset\n",
    "    \n",
    "    Returns:\n",
    "    - quality_metrics: dictionary containing all quality metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic metrics\n",
    "    total_rows = df.shape[0]\n",
    "    total_columns = df.shape[1]\n",
    "    total_cells = total_rows * total_columns\n",
    "    \n",
    "    # Missing data metrics\n",
    "    missing_cells = df.isnull().sum().sum()\n",
    "    missing_ratio = missing_cells / total_cells if total_cells > 0 else 0\n",
    "    completeness_score = (1 - missing_ratio) * 100\n",
    "    \n",
    "    # Duplicate analysis\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    duplicate_ratio = duplicate_rows / total_rows if total_rows > 0 else 0\n",
    "    uniqueness_score = (1 - duplicate_ratio) * 100\n",
    "    \n",
    "    # Data type consistency (numeric vs object columns)\n",
    "    numeric_cols = len(df.select_dtypes(include=[np.number]).columns)\n",
    "    object_cols = len(df.select_dtypes(include=['object']).columns)\n",
    "    datetime_cols = len(df.select_dtypes(include=['datetime64']).columns)\n",
    "    \n",
    "    # Overall quality score (weighted average: 50% completeness, 50% uniqueness)\n",
    "    overall_quality = (completeness_score * 0.5 + uniqueness_score * 0.5)\n",
    "    \n",
    "    quality_metrics = {\n",
    "        'dataset_name': dataset_name,\n",
    "        'total_rows': total_rows,\n",
    "        'total_columns': total_columns,\n",
    "        'missing_cells': missing_cells,\n",
    "        'missing_ratio': missing_ratio,\n",
    "        'completeness_score': completeness_score,\n",
    "        'duplicate_rows': duplicate_rows,\n",
    "        'uniqueness_score': uniqueness_score,\n",
    "        'numeric_columns': numeric_cols,\n",
    "        'object_columns': object_cols,\n",
    "        'datetime_columns': datetime_cols,\n",
    "        'overall_quality_score': overall_quality\n",
    "    }\n",
    "    \n",
    "    return quality_metrics\n",
    "\n",
    "print(\"✅ Data quality metrics function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1231ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Display quality metrics function defined!\n"
     ]
    }
   ],
   "source": [
    "def display_quality_metrics(quality_metrics):\n",
    "    \"\"\"\n",
    "    Display data quality metrics in a formatted, professional way\n",
    "    \n",
    "    Parameters:\n",
    "    - quality_metrics: dictionary containing quality metrics from calculate_data_quality_metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n📊 DATA QUALITY METRICS:\")\n",
    "    print(f\"  🎯 Completeness Score: {quality_metrics['completeness_score']:.1f}%\")\n",
    "    print(f\"  🔄 Uniqueness Score: {quality_metrics['uniqueness_score']:.1f}%\")\n",
    "    print(f\"  🏆 Overall Quality Score: {quality_metrics['overall_quality_score']:.1f}%\")\n",
    "    \n",
    "    if quality_metrics['duplicate_rows'] > 0:\n",
    "        print(f\"  ⚠️  Duplicate rows: {quality_metrics['duplicate_rows']:,}\")\n",
    "    \n",
    "    # Quality assessment with visual indicators\n",
    "    score = quality_metrics['overall_quality_score']\n",
    "    if score >= 90:\n",
    "        quality_level = \"Excellent ⭐⭐⭐\"\n",
    "    elif score >= 75:\n",
    "        quality_level = \"Good ⭐⭐\"\n",
    "    elif score >= 60:\n",
    "        quality_level = \"Fair ⭐\"\n",
    "    else:\n",
    "        quality_level = \"Poor ⚠️\"\n",
    "    \n",
    "    print(f\"  📈 Quality Level: {quality_level}\")\n",
    "\n",
    "print(\"✅ Display quality metrics function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ff307",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading and Inspection Functions\n",
    "\n",
    "These functions handle the loading and comprehensive inspection of both CSV files and Excel files (including multi-sheet Excel files). They provide detailed information about each dataset's structure, data types, and quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ad434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comprehensive dataset display function defined!\n"
     ]
    }
   ],
   "source": [
    "def display_dataset_info(filename, dataset_name, df=None, excel_data=None):\n",
    "    \"\"\"\n",
    "    Display comprehensive information for a dataset (CSV or Excel with all sheets)\n",
    "    \n",
    "    Parameters:\n",
    "    - filename: name of the file\n",
    "    - dataset_name: clean name for display\n",
    "    - df: pandas DataFrame (for CSV files)\n",
    "    - excel_data: dictionary of DataFrames (for Excel files)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"DATASET: {dataset_name.upper()}\")\n",
    "    print(f\"File: {filename}\")\n",
    "    \n",
    "    # Handle CSV files\n",
    "    if df is not None and excel_data is None:\n",
    "        print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "        print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "        \n",
    "        print(f\"\\nColumn Names:\")\n",
    "        for i, col in enumerate(df.columns, 1):\n",
    "            print(f\"  {i:2d}. {col}\")\n",
    "        \n",
    "        print(f\"\\nData Types:\")\n",
    "        print(df.dtypes.value_counts())\n",
    "        \n",
    "        # Missing data analysis\n",
    "        print(f\"\\nMissing Data Analysis:\")\n",
    "        total_cells = df.shape[0] * df.shape[1]\n",
    "        missing_cells = df.isnull().sum().sum()\n",
    "        missing_percentage = (missing_cells / total_cells) * 100 if total_cells > 0 else 0\n",
    "        \n",
    "        print(f\"  • Total missing cells: {missing_cells:,} ({missing_percentage:.1f}%)\")\n",
    "        \n",
    "        # Calculate and display quality metrics for CSV\n",
    "        quality_metrics = calculate_data_quality_metrics(df, dataset_name)\n",
    "        display_quality_metrics(quality_metrics)\n",
    "    \n",
    "    # Handle Excel files with all sheets\n",
    "    elif excel_data is not None:\n",
    "        sheet_names = list(excel_data.keys())\n",
    "        total_sheets = len(sheet_names)\n",
    "        print(f\"📋 File Type: Excel with {total_sheets} sheet(s)\")\n",
    "        print(f\"📄 Sheet Names: {sheet_names}\")\n",
    "        \n",
    "        # Calculate total statistics across all sheets\n",
    "        total_rows = sum(excel_data[sheet].shape[0] for sheet in sheet_names)\n",
    "        total_memory = sum(excel_data[sheet].memory_usage(deep=True).sum() for sheet in sheet_names) / 1024**2\n",
    "        \n",
    "        print(f\"📊 Total Data: {total_rows:,} rows across all sheets\")\n",
    "        print(f\"💾 Total Memory usage: {total_memory:.2f} MB\")\n",
    "        \n",
    "        # Display information for each sheet\n",
    "        for i, sheet_name in enumerate(sheet_names, 1):\n",
    "            sheet_df = excel_data[sheet_name]\n",
    "            print(f\"\\n{'-'*50}\")\n",
    "            print(f\"SHEET {i}/{total_sheets}: {sheet_name.upper()}\")\n",
    "            print(f\"{'-'*50}\")\n",
    "            print(f\"📊 Shape: {sheet_df.shape[0]:,} rows × {sheet_df.shape[1]} columns\")\n",
    "            \n",
    "            print(f\"\\n📋 Column Names:\")\n",
    "            for j, col in enumerate(sheet_df.columns, 1):\n",
    "                print(f\"  {j:2d}. {col}\")\n",
    "            \n",
    "            print(f\"\\n🔍 Data Types:\")\n",
    "            print(sheet_df.dtypes.value_counts())\n",
    "            \n",
    "            # Missing data analysis for each sheet\n",
    "            print(f\"\\n🕳️  Missing Data Analysis:\")\n",
    "            total_cells = sheet_df.shape[0] * sheet_df.shape[1]\n",
    "            missing_cells = sheet_df.isnull().sum().sum()\n",
    "            missing_percentage = (missing_cells / total_cells) * 100 if total_cells > 0 else 0\n",
    "            \n",
    "            print(f\"  • Total missing cells: {missing_cells:,} ({missing_percentage:.1f}%)\")\n",
    "            \n",
    "            # Calculate and display quality metrics for each sheet\n",
    "            sheet_quality_metrics = calculate_data_quality_metrics(sheet_df, f\"{dataset_name}_{sheet_name}\")\n",
    "            display_quality_metrics(sheet_quality_metrics)\n",
    "        \n",
    "        # Calculate overall quality metrics for the entire Excel file (all sheets combined)\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"OVERALL FILE QUALITY: {dataset_name.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Combine all sheets into one large DataFrame for overall analysis\n",
    "        combined_df = pd.concat(excel_data.values(), ignore_index=True)\n",
    "        overall_quality_metrics = calculate_data_quality_metrics(combined_df, f\"{dataset_name}_OVERALL\")\n",
    "        \n",
    "        print(f\"📊 Combined Analysis Across All {total_sheets} Sheets:\")\n",
    "        display_quality_metrics(overall_quality_metrics)\n",
    "\n",
    "print(\"✅ Comprehensive dataset display function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb053bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loading function defined!\n"
     ]
    }
   ],
   "source": [
    "def load_and_inspect_dataset(filename, dataset_name):\n",
    "    \"\"\"\n",
    "    Load dataset and return basic information\n",
    "    Handles both CSV and Excel files (including multi-sheet Excel files)\n",
    "    \n",
    "    Parameters:\n",
    "    - filename: name of the file to load\n",
    "    - dataset_name: clean name for the dataset\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (success_boolean, message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        \n",
    "        # Load dataset based on file extension\n",
    "        if filename.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Store dataset in global dictionary\n",
    "            datasets[dataset_name] = df\n",
    "            \n",
    "            # Display comprehensive information for CSV\n",
    "            display_dataset_info(filename, dataset_name, df=df)\n",
    "            \n",
    "            return True, \"Success\"\n",
    "            \n",
    "        elif filename.endswith('.xlsx') or filename.endswith('.xls'):\n",
    "            # Load all sheets from Excel file\n",
    "            excel_file = pd.ExcelFile(file_path)\n",
    "            sheet_names = excel_file.sheet_names\n",
    "            \n",
    "            # Load all sheets into a dictionary\n",
    "            excel_data = {}\n",
    "            for sheet_name in sheet_names:\n",
    "                sheet_df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "                excel_data[sheet_name] = sheet_df\n",
    "                \n",
    "                # Store each sheet individually in datasets dictionary\n",
    "                if len(sheet_names) == 1:\n",
    "                    sheet_key = dataset_name\n",
    "                else:\n",
    "                    sheet_key = f\"{dataset_name}_{sheet_name}\"\n",
    "                datasets[sheet_key] = sheet_df\n",
    "            \n",
    "            # Display comprehensive information for all sheets\n",
    "            display_dataset_info(filename, dataset_name, excel_data=excel_data)\n",
    "            \n",
    "            return True, \"Success\"\n",
    "                \n",
    "        else:\n",
    "            return None, f\"Unsupported file format for {filename}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"Error loading {filename}: {str(e)}\"\n",
    "\n",
    "print(\"✅ Dataset loading function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b2c31",
   "metadata": {},
   "source": [
    "## 4. Dataset Loading and Evaluation Execution\n",
    "\n",
    "Now we'll execute our systematic evaluation process across all available datasets in the `Datasource/` directory. This will automatically discover, load, and evaluate each dataset using our comprehensive framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c5106",
   "metadata": {},
   "source": [
    "## 5. Evaluation Summary and Dataset Selection\n",
    "\n",
    "Based on our systematic evaluation, we can now make an informed decision about which dataset best meets our criteria for a senior-level data science portfolio project.\n",
    "\n",
    "### Key Findings:\n",
    "- **Data Quality Scores:** Calculated for completeness and uniqueness\n",
    "- **Business Relevance:** Assessed based on real-world applicability  \n",
    "- **Technical Complexity:** Evaluated for demonstration of diverse skills\n",
    "\n",
    "### Next Steps:\n",
    "1. Review the quality metrics above\n",
    "2. Select the optimal dataset based on our evaluation framework\n",
    "3. Proceed with comprehensive analysis of the selected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e60b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting systematic dataset evaluation...\n",
      "📁 Looking for datasets in: ../Datasource/\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DATASET: TITANIC PASSENGER LIST\n",
      "File: titanic passenger list.csv\n",
      "Shape: 1,309 rows × 14 columns\n",
      "Memory usage: 0.52 MB\n",
      "\n",
      "Column Names:\n",
      "   1. pclass\n",
      "   2. survived\n",
      "   3. name\n",
      "   4. sex\n",
      "   5. age\n",
      "   6. sibsp\n",
      "   7. parch\n",
      "   8. ticket\n",
      "   9. fare\n",
      "  10. cabin\n",
      "  11. embarked\n",
      "  12. boat\n",
      "  13. body\n",
      "  14. home.dest\n",
      "\n",
      "Data Types:\n",
      "object     7\n",
      "int64      4\n",
      "float64    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing Data Analysis:\n",
      "  • Total missing cells: 3,855 (21.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 79.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 89.5%\n",
      "  📈 Quality Level: Good ⭐⭐\n",
      "\n",
      "============================================================\n",
      "DATASET: TITANIC PASSENGER LIST\n",
      "File: titanic passenger list.csv\n",
      "Shape: 1,309 rows × 14 columns\n",
      "Memory usage: 0.52 MB\n",
      "\n",
      "Column Names:\n",
      "   1. pclass\n",
      "   2. survived\n",
      "   3. name\n",
      "   4. sex\n",
      "   5. age\n",
      "   6. sibsp\n",
      "   7. parch\n",
      "   8. ticket\n",
      "   9. fare\n",
      "  10. cabin\n",
      "  11. embarked\n",
      "  12. boat\n",
      "  13. body\n",
      "  14. home.dest\n",
      "\n",
      "Data Types:\n",
      "object     7\n",
      "int64      4\n",
      "float64    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing Data Analysis:\n",
      "  • Total missing cells: 3,855 (21.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 79.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 89.5%\n",
      "  📈 Quality Level: Good ⭐⭐\n",
      "\n",
      "============================================================\n",
      "DATASET: SPOTIFYFEATURES\n",
      "File: SpotifyFeatures.csv\n",
      "Shape: 232,725 rows × 18 columns\n",
      "Memory usage: 111.81 MB\n",
      "\n",
      "Column Names:\n",
      "   1. genre\n",
      "   2. artist_name\n",
      "   3. track_name\n",
      "   4. track_id\n",
      "   5. popularity\n",
      "   6. acousticness\n",
      "   7. danceability\n",
      "   8. duration_ms\n",
      "   9. energy\n",
      "  10. instrumentalness\n",
      "  11. key\n",
      "  12. liveness\n",
      "  13. loudness\n",
      "  14. mode\n",
      "  15. speechiness\n",
      "  16. tempo\n",
      "  17. time_signature\n",
      "  18. valence\n",
      "\n",
      "Data Types:\n",
      "float64    9\n",
      "object     7\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing Data Analysis:\n",
      "  • Total missing cells: 1 (0.0%)\n",
      "\n",
      "============================================================\n",
      "DATASET: SPOTIFYFEATURES\n",
      "File: SpotifyFeatures.csv\n",
      "Shape: 232,725 rows × 18 columns\n",
      "Memory usage: 111.81 MB\n",
      "\n",
      "Column Names:\n",
      "   1. genre\n",
      "   2. artist_name\n",
      "   3. track_name\n",
      "   4. track_id\n",
      "   5. popularity\n",
      "   6. acousticness\n",
      "   7. danceability\n",
      "   8. duration_ms\n",
      "   9. energy\n",
      "  10. instrumentalness\n",
      "  11. key\n",
      "  12. liveness\n",
      "  13. loudness\n",
      "  14. mode\n",
      "  15. speechiness\n",
      "  16. tempo\n",
      "  17. time_signature\n",
      "  18. valence\n",
      "\n",
      "Data Types:\n",
      "float64    9\n",
      "object     7\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing Data Analysis:\n",
      "  • Total missing cells: 1 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "============================================================\n",
      "DATASET: AI_ADOPTION_DATASET\n",
      "File: ai_adoption_dataset.csv\n",
      "Shape: 145,000 rows × 9 columns\n",
      "Memory usage: 69.72 MB\n",
      "\n",
      "Column Names:\n",
      "   1. country\n",
      "   2. industry\n",
      "   3. ai_tool\n",
      "   4. adoption_rate\n",
      "   5. daily_active_users\n",
      "   6. year\n",
      "   7. user_feedback\n",
      "   8. age_group\n",
      "   9. company_size\n",
      "\n",
      "Data Types:\n",
      "object     6\n",
      "int64      2\n",
      "float64    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "============================================================\n",
      "DATASET: AI_ADOPTION_DATASET\n",
      "File: ai_adoption_dataset.csv\n",
      "Shape: 145,000 rows × 9 columns\n",
      "Memory usage: 69.72 MB\n",
      "\n",
      "Column Names:\n",
      "   1. country\n",
      "   2. industry\n",
      "   3. ai_tool\n",
      "   4. adoption_rate\n",
      "   5. daily_active_users\n",
      "   6. year\n",
      "   7. user_feedback\n",
      "   8. age_group\n",
      "   9. company_size\n",
      "\n",
      "Data Types:\n",
      "object     6\n",
      "int64      2\n",
      "float64    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "============================================================\n",
      "DATASET: SAMPLE_-_SUPERSTORE\n",
      "File: sample_-_superstore.xls\n",
      "📋 File Type: Excel with 3 sheet(s)\n",
      "📄 Sheet Names: ['Orders', 'Returns', 'People']\n",
      "📊 Total Data: 10,294 rows across all sheets\n",
      "💾 Total Memory usage: 8.29 MB\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 1/3: ORDERS\n",
      "--------------------------------------------------\n",
      "📊 Shape: 9,994 rows × 21 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. Row ID\n",
      "   2. Order ID\n",
      "   3. Order Date\n",
      "   4. Ship Date\n",
      "   5. Ship Mode\n",
      "   6. Customer ID\n",
      "   7. Customer Name\n",
      "   8. Segment\n",
      "   9. Country\n",
      "  10. City\n",
      "  11. State\n",
      "  12. Postal Code\n",
      "  13. Region\n",
      "  14. Product ID\n",
      "  15. Category\n",
      "  16. Sub-Category\n",
      "  17. Product Name\n",
      "  18. Sales\n",
      "  19. Quantity\n",
      "  20. Discount\n",
      "  21. Profit\n",
      "\n",
      "🔍 Data Types:\n",
      "object            13\n",
      "int64              3\n",
      "float64            3\n",
      "datetime64[ns]     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 2/3: RETURNS\n",
      "--------------------------------------------------\n",
      "📊 Shape: 296 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. Returned\n",
      "   2. Order ID\n",
      "\n",
      "🔍 Data Types:\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 3/3: PEOPLE\n",
      "--------------------------------------------------\n",
      "📊 Shape: 4 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. Person\n",
      "   2. Region\n",
      "\n",
      "🔍 Data Types:\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "==================================================\n",
      "OVERALL FILE QUALITY: SAMPLE_-_SUPERSTORE\n",
      "==================================================\n",
      "📊 Combined Analysis Across All 3 Sheets:\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 88.9%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 94.4%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "============================================================\n",
      "DATASET: SAMPLE_-_SUPERSTORE\n",
      "File: sample_-_superstore.xls\n",
      "📋 File Type: Excel with 3 sheet(s)\n",
      "📄 Sheet Names: ['Orders', 'Returns', 'People']\n",
      "📊 Total Data: 10,294 rows across all sheets\n",
      "💾 Total Memory usage: 8.29 MB\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 1/3: ORDERS\n",
      "--------------------------------------------------\n",
      "📊 Shape: 9,994 rows × 21 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. Row ID\n",
      "   2. Order ID\n",
      "   3. Order Date\n",
      "   4. Ship Date\n",
      "   5. Ship Mode\n",
      "   6. Customer ID\n",
      "   7. Customer Name\n",
      "   8. Segment\n",
      "   9. Country\n",
      "  10. City\n",
      "  11. State\n",
      "  12. Postal Code\n",
      "  13. Region\n",
      "  14. Product ID\n",
      "  15. Category\n",
      "  16. Sub-Category\n",
      "  17. Product Name\n",
      "  18. Sales\n",
      "  19. Quantity\n",
      "  20. Discount\n",
      "  21. Profit\n",
      "\n",
      "🔍 Data Types:\n",
      "object            13\n",
      "int64              3\n",
      "float64            3\n",
      "datetime64[ns]     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 2/3: RETURNS\n",
      "--------------------------------------------------\n",
      "📊 Shape: 296 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. Returned\n",
      "   2. Order ID\n",
      "\n",
      "🔍 Data Types:\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 3/3: PEOPLE\n",
      "--------------------------------------------------\n",
      "📊 Shape: 4 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. Person\n",
      "   2. Region\n",
      "\n",
      "🔍 Data Types:\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "==================================================\n",
      "OVERALL FILE QUALITY: SAMPLE_-_SUPERSTORE\n",
      "==================================================\n",
      "📊 Combined Analysis Across All 3 Sheets:\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 88.9%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 94.4%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "============================================================\n",
      "DATASET: NETFLIX_TITLES\n",
      "File: netflix_titles.xlsx\n",
      "📋 File Type: Excel with 5 sheet(s)\n",
      "📄 Sheet Names: ['netflix_titles', 'netflix_titles_directors', 'netflix_titles_countries', 'netflix_titles_cast', 'netflix_titles_category']\n",
      "📊 Total Data: 76,248 rows across all sheets\n",
      "💾 Total Memory usage: 7.84 MB\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 1/5: NETFLIX_TITLES\n",
      "--------------------------------------------------\n",
      "📊 Shape: 6,236 rows × 9 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. duration_minutes\n",
      "   2. duration_seasons\n",
      "   3. type\n",
      "   4. title\n",
      "   5. date_added\n",
      "   6. release_year\n",
      "   7. rating\n",
      "   8. description\n",
      "   9. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object     7\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 6,271 (11.2%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 88.8%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 94.4%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 2/5: NETFLIX_TITLES_DIRECTORS\n",
      "--------------------------------------------------\n",
      "📊 Shape: 4,852 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. director\n",
      "   2. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object    1\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  ⚠️  Duplicate rows: 1\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 3/5: NETFLIX_TITLES_COUNTRIES\n",
      "--------------------------------------------------\n",
      "📊 Shape: 7,179 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. country\n",
      "   2. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object    1\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 4/5: NETFLIX_TITLES_CAST\n",
      "--------------------------------------------------\n",
      "📊 Shape: 44,311 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. cast\n",
      "   2. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object    1\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  ⚠️  Duplicate rows: 1\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 5/5: NETFLIX_TITLES_CATEGORY\n",
      "--------------------------------------------------\n",
      "📊 Shape: 13,670 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. listed_in\n",
      "   2. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object    1\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "==================================================\n",
      "OVERALL FILE QUALITY: NETFLIX_TITLES\n",
      "==================================================\n",
      "\n",
      "============================================================\n",
      "DATASET: NETFLIX_TITLES\n",
      "File: netflix_titles.xlsx\n",
      "📋 File Type: Excel with 5 sheet(s)\n",
      "📄 Sheet Names: ['netflix_titles', 'netflix_titles_directors', 'netflix_titles_countries', 'netflix_titles_cast', 'netflix_titles_category']\n",
      "📊 Total Data: 76,248 rows across all sheets\n",
      "💾 Total Memory usage: 7.84 MB\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 1/5: NETFLIX_TITLES\n",
      "--------------------------------------------------\n",
      "📊 Shape: 6,236 rows × 9 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. duration_minutes\n",
      "   2. duration_seasons\n",
      "   3. type\n",
      "   4. title\n",
      "   5. date_added\n",
      "   6. release_year\n",
      "   7. rating\n",
      "   8. description\n",
      "   9. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object     7\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 6,271 (11.2%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 88.8%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 94.4%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 2/5: NETFLIX_TITLES_DIRECTORS\n",
      "--------------------------------------------------\n",
      "📊 Shape: 4,852 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. director\n",
      "   2. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object    1\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  ⚠️  Duplicate rows: 1\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 3/5: NETFLIX_TITLES_COUNTRIES\n",
      "--------------------------------------------------\n",
      "📊 Shape: 7,179 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. country\n",
      "   2. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object    1\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 4/5: NETFLIX_TITLES_CAST\n",
      "--------------------------------------------------\n",
      "📊 Shape: 44,311 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. cast\n",
      "   2. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object    1\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  ⚠️  Duplicate rows: 1\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 5/5: NETFLIX_TITLES_CATEGORY\n",
      "--------------------------------------------------\n",
      "📊 Shape: 13,670 rows × 2 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. listed_in\n",
      "   2. show_id\n",
      "\n",
      "🔍 Data Types:\n",
      "object    1\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 0 (0.0%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 100.0%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 100.0%\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "==================================================\n",
      "OVERALL FILE QUALITY: NETFLIX_TITLES\n",
      "==================================================\n",
      "📊 Combined Analysis Across All 5 Sheets:\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 19.2%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 59.6%\n",
      "  ⚠️  Duplicate rows: 2\n",
      "  📈 Quality Level: Poor ⚠️\n",
      "📊 Combined Analysis Across All 5 Sheets:\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 19.2%\n",
      "  🔄 Uniqueness Score: 100.0%\n",
      "  🏆 Overall Quality Score: 59.6%\n",
      "  ⚠️  Duplicate rows: 2\n",
      "  📈 Quality Level: Poor ⚠️\n",
      "\n",
      "============================================================\n",
      "DATASET: AIRBNB\n",
      "File: airbnb.xlsx\n",
      "📋 File Type: Excel with 1 sheet(s)\n",
      "📄 Sheet Names: ['AirBnB_NYC']\n",
      "📊 Total Data: 30,478 rows across all sheets\n",
      "💾 Total Memory usage: 9.58 MB\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 1/1: AIRBNB_NYC\n",
      "--------------------------------------------------\n",
      "📊 Shape: 30,478 rows × 13 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. Host Id\n",
      "   2. Host Since\n",
      "   3. Name\n",
      "   4. Neighbourhood \n",
      "   5. Property Type\n",
      "   6. Review Scores Rating (bin)\n",
      "   7. Room Type\n",
      "   8. Zipcode\n",
      "   9. Beds\n",
      "  10. Number of Records\n",
      "  11. Number Of Reviews\n",
      "  12. Price\n",
      "  13. Review Scores Rating\n",
      "\n",
      "🔍 Data Types:\n",
      "int64             4\n",
      "object            4\n",
      "float64           4\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 16,871 (4.3%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 95.7%\n",
      "  🔄 Uniqueness Score: 99.9%\n",
      "  🏆 Overall Quality Score: 97.8%\n",
      "  ⚠️  Duplicate rows: 17\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "==================================================\n",
      "OVERALL FILE QUALITY: AIRBNB\n",
      "==================================================\n",
      "📊 Combined Analysis Across All 1 Sheets:\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 95.7%\n",
      "  🔄 Uniqueness Score: 99.9%\n",
      "  🏆 Overall Quality Score: 97.8%\n",
      "  ⚠️  Duplicate rows: 17\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "============================================================\n",
      "✅ EVALUATION COMPLETE!\n",
      "📊 Successfully loaded and evaluated 6 datasets from '../Datasource/'\n",
      "💾 All datasets stored in 'datasets' dictionary for further analysis\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DATASET: AIRBNB\n",
      "File: airbnb.xlsx\n",
      "📋 File Type: Excel with 1 sheet(s)\n",
      "📄 Sheet Names: ['AirBnB_NYC']\n",
      "📊 Total Data: 30,478 rows across all sheets\n",
      "💾 Total Memory usage: 9.58 MB\n",
      "\n",
      "--------------------------------------------------\n",
      "SHEET 1/1: AIRBNB_NYC\n",
      "--------------------------------------------------\n",
      "📊 Shape: 30,478 rows × 13 columns\n",
      "\n",
      "📋 Column Names:\n",
      "   1. Host Id\n",
      "   2. Host Since\n",
      "   3. Name\n",
      "   4. Neighbourhood \n",
      "   5. Property Type\n",
      "   6. Review Scores Rating (bin)\n",
      "   7. Room Type\n",
      "   8. Zipcode\n",
      "   9. Beds\n",
      "  10. Number of Records\n",
      "  11. Number Of Reviews\n",
      "  12. Price\n",
      "  13. Review Scores Rating\n",
      "\n",
      "🔍 Data Types:\n",
      "int64             4\n",
      "object            4\n",
      "float64           4\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🕳️  Missing Data Analysis:\n",
      "  • Total missing cells: 16,871 (4.3%)\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 95.7%\n",
      "  🔄 Uniqueness Score: 99.9%\n",
      "  🏆 Overall Quality Score: 97.8%\n",
      "  ⚠️  Duplicate rows: 17\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "==================================================\n",
      "OVERALL FILE QUALITY: AIRBNB\n",
      "==================================================\n",
      "📊 Combined Analysis Across All 1 Sheets:\n",
      "\n",
      "📊 DATA QUALITY METRICS:\n",
      "  🎯 Completeness Score: 95.7%\n",
      "  🔄 Uniqueness Score: 99.9%\n",
      "  🏆 Overall Quality Score: 97.8%\n",
      "  ⚠️  Duplicate rows: 17\n",
      "  📈 Quality Level: Excellent ⭐⭐⭐\n",
      "\n",
      "============================================================\n",
      "✅ EVALUATION COMPLETE!\n",
      "📊 Successfully loaded and evaluated 6 datasets from '../Datasource/'\n",
      "💾 All datasets stored in 'datasets' dictionary for further analysis\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize data path and storage\n",
    "data_path = \"../Datasource/\"  # Relative path from notebook location\n",
    "datasets = {}  # Dictionary to store all loaded datasets\n",
    "count = 0      # Counter for successfully loaded datasets\n",
    "\n",
    "print(\"🚀 Starting systematic dataset evaluation...\")\n",
    "print(f\"📁 Looking for datasets in: {data_path}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and evaluate all datasets from the specified directory\n",
    "for filename in os.listdir(data_path):\n",
    "    # Skip temporary files and hidden files\n",
    "    if filename.startswith('.') or filename.startswith('~$'):\n",
    "        continue\n",
    "        \n",
    "    # Only process supported file types\n",
    "    if not (filename.endswith('.csv') or filename.endswith('.xlsx') or filename.endswith('.xls')):\n",
    "        continue\n",
    "        \n",
    "    # Extract clean dataset name from filename\n",
    "    dataset_name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Load and inspect dataset\n",
    "    result, message = load_and_inspect_dataset(filename, dataset_name)\n",
    "    if result is None:\n",
    "        print(f\"❌ {message}\")\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✅ EVALUATION COMPLETE!\")\n",
    "print(f\"📊 Successfully loaded and evaluated {count} datasets from '{data_path}'\")\n",
    "print(f\"💾 All datasets stored in 'datasets' dictionary for further analysis\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 DATASET INVENTORY SUMMARY\n",
      "==================================================\n",
      "Total datasets loaded: 12\n",
      "\n",
      "Dataset keys in memory:\n",
      "   1. SpotifyFeatures: 232,725 rows × 18 columns\n",
      "   2. ai_adoption_dataset: 145,000 rows × 9 columns\n",
      "   3. airbnb: 30,478 rows × 13 columns\n",
      "   4. netflix_titles_netflix_titles: 6,236 rows × 9 columns\n",
      "   5. netflix_titles_netflix_titles_cast: 44,311 rows × 2 columns\n",
      "   6. netflix_titles_netflix_titles_category: 13,670 rows × 2 columns\n",
      "   7. netflix_titles_netflix_titles_countries: 7,179 rows × 2 columns\n",
      "   8. netflix_titles_netflix_titles_directors: 4,852 rows × 2 columns\n",
      "   9. sample_-_superstore_Orders: 9,994 rows × 21 columns\n",
      "  10. sample_-_superstore_People: 4 rows × 2 columns\n",
      "  11. sample_-_superstore_Returns: 296 rows × 2 columns\n",
      "  12. titanic passenger list: 1,309 rows × 14 columns\n",
      "\n",
      "==================================================\n",
      "🎯 RECOMMENDATION: Based on our systematic evaluation,\n",
      "the AIRBNB dataset provides the optimal balance of:\n",
      "✅ High data quality (97.8% overall score)\n",
      "✅ Strong business relevance (real estate/hospitality)\n",
      "✅ Technical complexity (geospatial, pricing, multi-feature)\n",
      "✅ Portfolio impact (demonstrates diverse DS skills)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Display summary of all loaded datasets\n",
    "print(\"📋 DATASET INVENTORY SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total datasets loaded: {len(datasets)}\")\n",
    "print(\"\\nDataset keys in memory:\")\n",
    "for i, dataset_key in enumerate(sorted(datasets.keys()), 1):\n",
    "    df = datasets[dataset_key]\n",
    "    print(f\"  {i:2d}. {dataset_key}: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🎯 RECOMMENDATION: Based on our systematic evaluation,\")\n",
    "print(\"the AIRBNB dataset provides the optimal balance of:\")\n",
    "print(\"✅ High data quality (97.8% overall score)\")\n",
    "print(\"✅ Strong business relevance (pricing/location/beds/room types/Property Type)\")  \n",
    "print(\"✅ Technical complexity (geospatial, pricing, multi-feature)\")\n",
    "print(\"✅ Portfolio impact (demonstrates diverse DS skills)\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
